12/01/2025 18:36:29 - INFO - training.fm_trainer - Starting training
12/01/2025 18:36:29 - INFO - training.fm_trainer -   Max steps: 1
12/01/2025 18:36:29 - INFO - training.fm_trainer -   Global batch size: 128
12/01/2025 18:36:29 - INFO - training.fm_trainer -   Gradient accumulation steps: 4
Traceback (most recent call last):
  File "/workspace/flow-matching/CoDA/flow-matching-qwen/training/train_h100.py", line 285, in <module>
    main()
  File "/workspace/flow-matching/CoDA/flow-matching-qwen/training/train_h100.py", line 281, in main
    trainer.train()
  File "/workspace/flow-matching/CoDA/flow-matching-qwen/training/fm_trainer.py", line 317, in train
    batch = next(train_iterator)
            ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py", line 866, in __iter__
    next_batch, next_batch_info = self._fetch_batches(main_iterator)
                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py", line 820, in _fetch_batches
    batches.append(next(iterator))
                   ^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py", line 734, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py", line 1516, in _next_data
    return self._process_data(data, worker_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py", line 1551, in _process_data
    data.reraise()
  File "/usr/local/lib/python3.12/dist-packages/torch/_utils.py", line 769, in reraise
    raise exception
ValueError: Caught ValueError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
           ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
    data.append(next(self.dataset_iter))
                ^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/flow-matching/CoDA/flow-matching-qwen/data/data_loader.py", line 391, in __iter__
    dataset = self._get_dataset()
              ^^^^^^^^^^^^^^^^^^^
  File "/workspace/flow-matching/CoDA/flow-matching-qwen/data/data_loader.py", line 339, in _get_dataset
    self._dataset = create_pretrain_mixture(
                    ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/flow-matching/CoDA/flow-matching-qwen/data/data_loader.py", line 295, in create_pretrain_mixture
    mixed_dataset = interleave_datasets(
                    ^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/combine.py", line 153, in interleave_datasets
    return _interleave_iterable_datasets(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 2322, in _interleave_iterable_datasets
    datasets = [d._resolve_features() for d in datasets]
                ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 2216, in _resolve_features
    features = _infer_features_from_batch(self.with_format(None)._head())
                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1239, in _head
    return _examples_to_batch(list(self.take(n)))
                              ^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1368, in __iter__
    yield from self._iter_pytorch()
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1303, in _iter_pytorch
    for key, example in ex_iterable:
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1044, in __iter__
    yield from islice(self.ex_iterable, self.n)
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 679, in __iter__
    yield from self._iter()
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 741, in _iter
    for key, example in iterator:
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1119, in __iter__
    for key, example in self.ex_iterable:
  File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 282, in __iter__
    for key, pa_table in self.generate_tables_fn(**self.kwargs):
  File "/usr/local/lib/python3.12/dist-packages/datasets/packaged_modules/json/json.py", line 79, in _generate_tables
    for file_idx, file in enumerate(itertools.chain.from_iterable(files)):
  File "/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py", line 1574, in __iter__
    for x in self.generator(*self.args, **self.kwargs):
  File "/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py", line 1655, in _iter_from_urlpaths
    if xisfile(urlpath, download_config=download_config):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py", line 1021, in xisfile
    fs, *_ = url_to_fs(path, **storage_options)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 395, in url_to_fs
    fs = filesystem(protocol, **inkwargs)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/fsspec/registry.py", line 293, in filesystem
    return cls(**storage_options)
           ^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/fsspec/spec.py", line 80, in __call__
    obj = super().__call__(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/datasets/filesystems/compression.py", line 36, in __init__
    self.file = fsspec.open(
                ^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 461, in open
    out = open_files(
          ^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 303, in open_files
    OpenFile(
  File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 77, in __init__
    self.compression = get_compression(path, compression)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 513, in get_compression
    raise ValueError(f"Compression type {compression} not supported")
ValueError: Compression type zstd not supported

[rank0]: Traceback (most recent call last):
[rank0]:   File "/workspace/flow-matching/CoDA/flow-matching-qwen/training/train_h100.py", line 285, in <module>
[rank0]:     main()
[rank0]:   File "/workspace/flow-matching/CoDA/flow-matching-qwen/training/train_h100.py", line 281, in main
[rank0]:     trainer.train()
[rank0]:   File "/workspace/flow-matching/CoDA/flow-matching-qwen/training/fm_trainer.py", line 317, in train
[rank0]:     batch = next(train_iterator)
[rank0]:             ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py", line 866, in __iter__
[rank0]:     next_batch, next_batch_info = self._fetch_batches(main_iterator)
[rank0]:                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/accelerate/data_loader.py", line 820, in _fetch_batches
[rank0]:     batches.append(next(iterator))
[rank0]:                    ^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py", line 734, in __next__
[rank0]:     data = self._next_data()
[rank0]:            ^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py", line 1516, in _next_data
[rank0]:     return self._process_data(data, worker_id)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py", line 1551, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/_utils.py", line 769, in reraise
[rank0]:     raise exception
[rank0]: ValueError: Caught ValueError in DataLoader worker process 0.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
[rank0]:     data.append(next(self.dataset_iter))
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/flow-matching/CoDA/flow-matching-qwen/data/data_loader.py", line 391, in __iter__
[rank0]:     dataset = self._get_dataset()
[rank0]:               ^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/flow-matching/CoDA/flow-matching-qwen/data/data_loader.py", line 339, in _get_dataset
[rank0]:     self._dataset = create_pretrain_mixture(
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/flow-matching/CoDA/flow-matching-qwen/data/data_loader.py", line 295, in create_pretrain_mixture
[rank0]:     mixed_dataset = interleave_datasets(
[rank0]:                     ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/combine.py", line 153, in interleave_datasets
[rank0]:     return _interleave_iterable_datasets(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 2322, in _interleave_iterable_datasets
[rank0]:     datasets = [d._resolve_features() for d in datasets]
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 2216, in _resolve_features
[rank0]:     features = _infer_features_from_batch(self.with_format(None)._head())
[rank0]:                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1239, in _head
[rank0]:     return _examples_to_batch(list(self.take(n)))
[rank0]:                               ^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1368, in __iter__
[rank0]:     yield from self._iter_pytorch()
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1303, in _iter_pytorch
[rank0]:     for key, example in ex_iterable:
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1044, in __iter__
[rank0]:     yield from islice(self.ex_iterable, self.n)
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 679, in __iter__
[rank0]:     yield from self._iter()
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 741, in _iter
[rank0]:     for key, example in iterator:
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 1119, in __iter__
[rank0]:     for key, example in self.ex_iterable:
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/iterable_dataset.py", line 282, in __iter__
[rank0]:     for key, pa_table in self.generate_tables_fn(**self.kwargs):
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/packaged_modules/json/json.py", line 79, in _generate_tables
[rank0]:     for file_idx, file in enumerate(itertools.chain.from_iterable(files)):
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py", line 1574, in __iter__
[rank0]:     for x in self.generator(*self.args, **self.kwargs):
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py", line 1655, in _iter_from_urlpaths
[rank0]:     if xisfile(urlpath, download_config=download_config):
[rank0]:        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/utils/file_utils.py", line 1021, in xisfile
[rank0]:     fs, *_ = url_to_fs(path, **storage_options)
[rank0]:              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 395, in url_to_fs
[rank0]:     fs = filesystem(protocol, **inkwargs)
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/registry.py", line 293, in filesystem
[rank0]:     return cls(**storage_options)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/spec.py", line 80, in __call__
[rank0]:     obj = super().__call__(*args, **kwargs)
[rank0]:           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/datasets/filesystems/compression.py", line 36, in __init__
[rank0]:     self.file = fsspec.open(
[rank0]:                 ^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 461, in open
[rank0]:     out = open_files(
[rank0]:           ^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 303, in open_files
[rank0]:     OpenFile(
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 77, in __init__
[rank0]:     self.compression = get_compression(path, compression)
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.12/dist-packages/fsspec/core.py", line 513, in get_compression
[rank0]:     raise ValueError(f"Compression type {compression} not supported")
[rank0]: ValueError: Compression type zstd not supported
